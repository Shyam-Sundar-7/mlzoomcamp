{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "Since we have a binary classification problem, what is the best loss function for us?\n",
    "\n",
    "- mean squared error\n",
    "- binary crossentropy\n",
    "- categorical crossentropy\n",
    "- cosine similarity\n",
    "\n",
    "The best loss function is binary crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "def model_arc():\n",
    "    # Create a Sequential model\n",
    "    model = Sequential()\n",
    "\n",
    "    # Add the Convolutional layer with 32 filters, a (3, 3) kernel, and 'relu' activation\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
    "\n",
    "    # Add MaxPooling layer with (2, 2) pool size\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # Flatten the multi-dimensional result\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # Add a Dense layer with 64 neurons and 'relu' activation\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "\n",
    "    # Add the output Dense layer with 1 neuron for binary classification\n",
    "    # Use 'sigmoid' activation for binary classification\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Define the optimizer with the specified parameters\n",
    "    sgd = SGD(learning_rate=0.002, momentum=0.8)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3677 images belonging to 2 classes.\n",
      "Found 918 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_ds = train_gen.flow_from_directory(\n",
    "    'data/train',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_ds = test_gen.flow_from_directory(\n",
    "    './data/test',\n",
    "    shuffle=True,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model=model_arc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "184/184 [==============================] - 21s 114ms/step - loss: 0.5688 - accuracy: 0.7063 - val_loss: 0.5583 - val_accuracy: 0.7113\n",
      "Epoch 2/10\n",
      "184/184 [==============================] - 21s 112ms/step - loss: 0.5393 - accuracy: 0.7318 - val_loss: 0.5454 - val_accuracy: 0.7571\n",
      "Epoch 3/10\n",
      "184/184 [==============================] - 20s 110ms/step - loss: 0.5181 - accuracy: 0.7525 - val_loss: 0.5434 - val_accuracy: 0.7549\n",
      "Epoch 4/10\n",
      "184/184 [==============================] - 22s 117ms/step - loss: 0.4967 - accuracy: 0.7792 - val_loss: 0.5709 - val_accuracy: 0.7037\n",
      "Epoch 5/10\n",
      "184/184 [==============================] - 21s 116ms/step - loss: 0.4828 - accuracy: 0.7827 - val_loss: 0.5456 - val_accuracy: 0.7255\n",
      "Epoch 6/10\n",
      "184/184 [==============================] - 21s 115ms/step - loss: 0.4648 - accuracy: 0.7958 - val_loss: 0.5292 - val_accuracy: 0.7451\n",
      "Epoch 7/10\n",
      "184/184 [==============================] - 21s 115ms/step - loss: 0.4349 - accuracy: 0.8162 - val_loss: 0.5240 - val_accuracy: 0.7462\n",
      "Epoch 8/10\n",
      "184/184 [==============================] - 20s 109ms/step - loss: 0.4057 - accuracy: 0.8300 - val_loss: 0.4954 - val_accuracy: 0.7734\n",
      "Epoch 9/10\n",
      "184/184 [==============================] - 20s 108ms/step - loss: 0.3841 - accuracy: 0.8393 - val_loss: 0.5151 - val_accuracy: 0.7527\n",
      "Epoch 10/10\n",
      "184/184 [==============================] - 20s 108ms/step - loss: 0.3518 - accuracy: 0.8564 - val_loss: 0.5128 - val_accuracy: 0.7505\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(\n",
    "    train_ds,\n",
    "    epochs=10,\n",
    "    validation_data=test_ds\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "What's the number of parameters in the convolutional layer of our model? You can use the summary method for that.\n",
    "\n",
    "- 1\n",
    "- 65\n",
    "- 896\n",
    "- 11214912\n",
    "\n",
    "\n",
    "11214912"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 74, 74, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 175232)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                11214912  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11215873 (42.79 MB)\n",
      "Trainable params: 11215873 (42.79 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "What is the median of training accuracy for all the epochs for this model?\n",
    "\n",
    "- 0.20\n",
    "- 0.40\n",
    "- 0.60\n",
    "- 0.80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7892303466796875\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "accuracy_values = history.history['accuracy']\n",
    "median_value = np.median(accuracy_values)\n",
    "print(median_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "What is the standard deviation of training loss for all the epochs for this model?\n",
    "\n",
    "- 0.031\n",
    "- 0.061\n",
    "- 0.091\n",
    "- 0.131"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06649431052261491\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "loss_values = history.history['loss']\n",
    "std = np.std(loss_values)\n",
    "print(std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3677 images belonging to 2 classes.\n",
      "Found 918 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    rotation_range=50,         # Randomly rotate images up to 50 degrees\n",
    "    width_shift_range=0.1,     # Randomly shift the width of the images by up to 10%\n",
    "    height_shift_range=0.1,    # Randomly shift the height of the images by up to 10%\n",
    "    zoom_range=0.1,            # Randomly zoom in or out by up to 10%\n",
    "    horizontal_flip=True,      # Randomly flip images horizontally\n",
    "    fill_mode='nearest'        # Fill in new pixels with the nearest existing pixel value\n",
    ")\n",
    "\n",
    "train_ds = train_gen.flow_from_directory(\n",
    "    'data/train',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_ds = test_gen.flow_from_directory(\n",
    "    './data/test',\n",
    "    shuffle=True,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "184/184 [==============================] - 22s 117ms/step - loss: 0.3280 - accuracy: 0.8730 - val_loss: 0.5056 - val_accuracy: 0.7625\n",
      "Epoch 2/10\n",
      "184/184 [==============================] - 21s 115ms/step - loss: 0.2933 - accuracy: 0.8920 - val_loss: 0.5413 - val_accuracy: 0.7440\n",
      "Epoch 3/10\n",
      "184/184 [==============================] - 22s 117ms/step - loss: 0.2709 - accuracy: 0.8996 - val_loss: 0.5550 - val_accuracy: 0.7756\n",
      "Epoch 4/10\n",
      "184/184 [==============================] - 21s 115ms/step - loss: 0.2508 - accuracy: 0.9100 - val_loss: 0.5571 - val_accuracy: 0.7734\n",
      "Epoch 5/10\n",
      "184/184 [==============================] - 21s 116ms/step - loss: 0.2103 - accuracy: 0.9293 - val_loss: 0.5847 - val_accuracy: 0.7712\n",
      "Epoch 6/10\n",
      "184/184 [==============================] - 22s 119ms/step - loss: 0.1739 - accuracy: 0.9434 - val_loss: 0.6406 - val_accuracy: 0.7495\n",
      "Epoch 7/10\n",
      "184/184 [==============================] - 21s 116ms/step - loss: 0.1491 - accuracy: 0.9600 - val_loss: 0.6394 - val_accuracy: 0.7364\n",
      "Epoch 8/10\n",
      "184/184 [==============================] - 21s 113ms/step - loss: 0.1356 - accuracy: 0.9611 - val_loss: 0.7188 - val_accuracy: 0.7124\n",
      "Epoch 9/10\n",
      "184/184 [==============================] - 22s 118ms/step - loss: 0.1078 - accuracy: 0.9725 - val_loss: 0.6533 - val_accuracy: 0.7527\n",
      "Epoch 10/10\n",
      "184/184 [==============================] - 21s 114ms/step - loss: 0.0941 - accuracy: 0.9796 - val_loss: 0.6699 - val_accuracy: 0.7712\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(\n",
    "    train_ds,\n",
    "    epochs=10,\n",
    "    validation_data=test_ds\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5\n",
    "Let's train our model for 10 more epochs using the same code as previously.\n",
    "\n",
    "What is the mean of test loss for all the epochs for the model trained with augmentations?\n",
    "\n",
    "- 0.18\n",
    "- 0.48\n",
    "- 0.78\n",
    "- 0.108"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6065710604190826\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "val_loss = history.history['val_loss']\n",
    "mean_value = np.mean(val_loss)\n",
    "print(mean_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6\n",
    "What's the average of test accuracy for the last 5 epochs (from 6 to 10) for the model trained with augmentations?\n",
    "\n",
    "- 0.38\n",
    "- 0.58\n",
    "- 0.78\n",
    "- 0.98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7444444537162781\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "val_acc = history.history['val_accuracy'][5:]\n",
    "acc_mean = np.mean(val_acc)\n",
    "print(acc_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
